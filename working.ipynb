{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from collections import Counter\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import csv\n",
    "\n",
    "import multiprocessing\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rc('font', size=14)\n",
    "import seaborn as sns\n",
    "sns.set(style='whitegrid', color_codes=True, rc={'figure.figsize':(11,8)}, font_scale=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.chdir('/c/Users/matth/Documents/Coding/spotify/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Tidying Streaming Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read streaming data and concat rows\n",
    "strm_base = pd.DataFrame()\n",
    "for file in os.listdir(\"./data\"):\n",
    "    if file.startswith(\"Streaming\"):\n",
    "        file_path = \"./data/\" + file\n",
    "        temp = pd.read_json(file_path)\n",
    "        strm_base = pd.concat([strm_base,temp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>endTime</th>\n",
       "      <th>artistName</th>\n",
       "      <th>trackName</th>\n",
       "      <th>msPlayed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-06-23 22:28</td>\n",
       "      <td>Aiobahn</td>\n",
       "      <td>過ぎゆく日と君へ</td>\n",
       "      <td>6290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-05-08 05:06</td>\n",
       "      <td>Smallpools</td>\n",
       "      <td>Insincere</td>\n",
       "      <td>125825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-05-10 00:25</td>\n",
       "      <td>Smallpools</td>\n",
       "      <td>cycle</td>\n",
       "      <td>149040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-05-10 02:22</td>\n",
       "      <td>Nice White Parents</td>\n",
       "      <td>3: ‘This Is Our School, How Dare You?’</td>\n",
       "      <td>331310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-05-10 02:22</td>\n",
       "      <td>COIN</td>\n",
       "      <td>Turnaround</td>\n",
       "      <td>14470</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            endTime          artistName  \\\n",
       "0  2020-06-23 22:28             Aiobahn   \n",
       "1  2021-05-08 05:06          Smallpools   \n",
       "2  2021-05-10 00:25          Smallpools   \n",
       "3  2021-05-10 02:22  Nice White Parents   \n",
       "4  2021-05-10 02:22                COIN   \n",
       "\n",
       "                                trackName  msPlayed  \n",
       "0                                過ぎゆく日と君へ      6290  \n",
       "1                               Insincere    125825  \n",
       "2                                   cycle    149040  \n",
       "3  3: ‘This Is Our School, How Dare You?’    331310  \n",
       "4                              Turnaround     14470  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strm_base.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tidying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 20586 entries, 0 to 585\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   endTime     20586 non-null  object\n",
      " 1   artistName  20586 non-null  object\n",
      " 2   trackName   20586 non-null  object\n",
      " 3   msPlayed    20586 non-null  int64 \n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 804.1+ KB\n"
     ]
    }
   ],
   "source": [
    "strm_base.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "strm_base.index = range(0,strm_base.shape[0])\n",
    "strm_base = strm_base.astype({'endTime': 'datetime64','artistName':'string','trackName':'string'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20586 entries, 0 to 20585\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype         \n",
      "---  ------      --------------  -----         \n",
      " 0   endTime     20586 non-null  datetime64[ns]\n",
      " 1   artistName  20586 non-null  string        \n",
      " 2   trackName   20586 non-null  string        \n",
      " 3   msPlayed    20586 non-null  int64         \n",
      "dtypes: datetime64[ns](1), int64(1), string(2)\n",
      "memory usage: 643.4 KB\n"
     ]
    }
   ],
   "source": [
    "strm_base.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spotify API\n",
    "### Initial Exploration\n",
    "#### Initializing spotify object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add your own credentials in dev_creds.py\n",
    "from dev_creds import get_creds, alt_creds\n",
    "cid, secret = get_creds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_credentials_manager = SpotifyClientCredentials(client_id=cid,client_secret=secret)\n",
    "sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29548aaefa2b41f695b01501f57a56a9\n",
      "3f15d47c280642a98fdd3db7b7648e50\n"
     ]
    }
   ],
   "source": [
    "print(cid)\n",
    "print(secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test code\n",
    "playlist_link = \"https://open.spotify.com/playlist/37i9dQZEVXbNG2KDcFcKOF?si=1333723a6eff4b7f\"\n",
    "playlist_URI = playlist_link.split(\"/\")[-1].split(\"?\")[0]\n",
    "track_uris = [x[\"track\"][\"uri\"] for x in sp.playlist_tracks(playlist_URI)[\"items\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring sp.search query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My program took 0.14682388305664062 to run\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "test = sp.search('move brb')\n",
    "\n",
    "print(\"My program took\", time.time() - start_time, \"to run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['tracks'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['href', 'items', 'limit', 'next', 'offset', 'previous', 'total'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['tracks'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['tracks']['total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test['tracks']['items'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['album', 'artists', 'available_markets', 'disc_number', 'duration_ms', 'explicit', 'external_ids', 'external_urls', 'href', 'id', 'is_local', 'name', 'popularity', 'preview_url', 'track_number', 'type', 'uri'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['tracks']['items'][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2Ryp5LkAWyJwRqoFd8N7Kk'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['tracks']['items'][0]['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'album_type': 'single',\n",
       " 'artists': [{'external_urls': {'spotify': 'https://open.spotify.com/artist/2XBiI8PjCnjJ3XKWtiKcvc'},\n",
       "   'href': 'https://api.spotify.com/v1/artists/2XBiI8PjCnjJ3XKWtiKcvc',\n",
       "   'id': '2XBiI8PjCnjJ3XKWtiKcvc',\n",
       "   'name': 'brb.',\n",
       "   'type': 'artist',\n",
       "   'uri': 'spotify:artist:2XBiI8PjCnjJ3XKWtiKcvc'}],\n",
       " 'available_markets': ['AD',\n",
       "  'AE',\n",
       "  'AG',\n",
       "  'AL',\n",
       "  'AM',\n",
       "  'AO',\n",
       "  'AR',\n",
       "  'AT',\n",
       "  'AU',\n",
       "  'AZ',\n",
       "  'BA',\n",
       "  'BB',\n",
       "  'BD',\n",
       "  'BE',\n",
       "  'BF',\n",
       "  'BG',\n",
       "  'BH',\n",
       "  'BI',\n",
       "  'BJ',\n",
       "  'BN',\n",
       "  'BO',\n",
       "  'BR',\n",
       "  'BS',\n",
       "  'BT',\n",
       "  'BW',\n",
       "  'BY',\n",
       "  'BZ',\n",
       "  'CA',\n",
       "  'CD',\n",
       "  'CG',\n",
       "  'CH',\n",
       "  'CI',\n",
       "  'CL',\n",
       "  'CM',\n",
       "  'CO',\n",
       "  'CR',\n",
       "  'CV',\n",
       "  'CW',\n",
       "  'CY',\n",
       "  'CZ',\n",
       "  'DE',\n",
       "  'DJ',\n",
       "  'DK',\n",
       "  'DM',\n",
       "  'DO',\n",
       "  'DZ',\n",
       "  'EC',\n",
       "  'EE',\n",
       "  'EG',\n",
       "  'ES',\n",
       "  'FI',\n",
       "  'FJ',\n",
       "  'FM',\n",
       "  'FR',\n",
       "  'GA',\n",
       "  'GB',\n",
       "  'GD',\n",
       "  'GE',\n",
       "  'GH',\n",
       "  'GM',\n",
       "  'GN',\n",
       "  'GQ',\n",
       "  'GR',\n",
       "  'GT',\n",
       "  'GW',\n",
       "  'GY',\n",
       "  'HK',\n",
       "  'HN',\n",
       "  'HR',\n",
       "  'HT',\n",
       "  'HU',\n",
       "  'ID',\n",
       "  'IE',\n",
       "  'IL',\n",
       "  'IN',\n",
       "  'IQ',\n",
       "  'IS',\n",
       "  'IT',\n",
       "  'JM',\n",
       "  'JO',\n",
       "  'JP',\n",
       "  'KE',\n",
       "  'KG',\n",
       "  'KH',\n",
       "  'KI',\n",
       "  'KM',\n",
       "  'KN',\n",
       "  'KR',\n",
       "  'KW',\n",
       "  'KZ',\n",
       "  'LA',\n",
       "  'LB',\n",
       "  'LC',\n",
       "  'LI',\n",
       "  'LK',\n",
       "  'LR',\n",
       "  'LS',\n",
       "  'LT',\n",
       "  'LU',\n",
       "  'LV',\n",
       "  'LY',\n",
       "  'MA',\n",
       "  'MC',\n",
       "  'MD',\n",
       "  'ME',\n",
       "  'MG',\n",
       "  'MH',\n",
       "  'MK',\n",
       "  'ML',\n",
       "  'MN',\n",
       "  'MO',\n",
       "  'MR',\n",
       "  'MT',\n",
       "  'MU',\n",
       "  'MV',\n",
       "  'MW',\n",
       "  'MX',\n",
       "  'MY',\n",
       "  'MZ',\n",
       "  'NA',\n",
       "  'NE',\n",
       "  'NG',\n",
       "  'NI',\n",
       "  'NL',\n",
       "  'NO',\n",
       "  'NP',\n",
       "  'NR',\n",
       "  'NZ',\n",
       "  'OM',\n",
       "  'PA',\n",
       "  'PE',\n",
       "  'PG',\n",
       "  'PH',\n",
       "  'PK',\n",
       "  'PL',\n",
       "  'PS',\n",
       "  'PT',\n",
       "  'PW',\n",
       "  'PY',\n",
       "  'QA',\n",
       "  'RO',\n",
       "  'RS',\n",
       "  'RW',\n",
       "  'SA',\n",
       "  'SB',\n",
       "  'SC',\n",
       "  'SE',\n",
       "  'SG',\n",
       "  'SI',\n",
       "  'SK',\n",
       "  'SL',\n",
       "  'SM',\n",
       "  'SN',\n",
       "  'SR',\n",
       "  'ST',\n",
       "  'SV',\n",
       "  'SZ',\n",
       "  'TD',\n",
       "  'TG',\n",
       "  'TH',\n",
       "  'TJ',\n",
       "  'TL',\n",
       "  'TN',\n",
       "  'TO',\n",
       "  'TR',\n",
       "  'TT',\n",
       "  'TV',\n",
       "  'TW',\n",
       "  'TZ',\n",
       "  'UA',\n",
       "  'UG',\n",
       "  'US',\n",
       "  'UY',\n",
       "  'UZ',\n",
       "  'VC',\n",
       "  'VE',\n",
       "  'VN',\n",
       "  'VU',\n",
       "  'WS',\n",
       "  'XK',\n",
       "  'ZA',\n",
       "  'ZM',\n",
       "  'ZW'],\n",
       " 'external_urls': {'spotify': 'https://open.spotify.com/album/1gaYhlmZa4fT0NfH1IiSQ4'},\n",
       " 'href': 'https://api.spotify.com/v1/albums/1gaYhlmZa4fT0NfH1IiSQ4',\n",
       " 'id': '1gaYhlmZa4fT0NfH1IiSQ4',\n",
       " 'images': [{'height': 640,\n",
       "   'url': 'https://i.scdn.co/image/ab67616d0000b273d1f9512c5b99ac3a3cee3868',\n",
       "   'width': 640},\n",
       "  {'height': 300,\n",
       "   'url': 'https://i.scdn.co/image/ab67616d00001e02d1f9512c5b99ac3a3cee3868',\n",
       "   'width': 300},\n",
       "  {'height': 64,\n",
       "   'url': 'https://i.scdn.co/image/ab67616d00004851d1f9512c5b99ac3a3cee3868',\n",
       "   'width': 64}],\n",
       " 'name': 'move',\n",
       " 'release_date': '2021-01-22',\n",
       " 'release_date_precision': 'day',\n",
       " 'total_tracks': 1,\n",
       " 'type': 'album',\n",
       " 'uri': 'spotify:album:1gaYhlmZa4fT0NfH1IiSQ4'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['tracks']['items'][0]['album']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1gaYhlmZa4fT0NfH1IiSQ4'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['tracks']['items'][0]['album']['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'external_urls': {'spotify': 'https://open.spotify.com/artist/2XBiI8PjCnjJ3XKWtiKcvc'},\n",
       "  'href': 'https://api.spotify.com/v1/artists/2XBiI8PjCnjJ3XKWtiKcvc',\n",
       "  'id': '2XBiI8PjCnjJ3XKWtiKcvc',\n",
       "  'name': 'brb.',\n",
       "  'type': 'artist',\n",
       "  'uri': 'spotify:artist:2XBiI8PjCnjJ3XKWtiKcvc'}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['tracks']['items'][0]['artists']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'move'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['tracks']['items'][0]['name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Findings\n",
    "The format of the search return appears to be a dictionary which starts with 'tracks' since we search tracks (default) and then the parameters of the search where 'items' are the songs returned. Items is a list of 10 since default limit=10 where each entry in the list is a dictionary. We want to extract the name and artist to match with our streaming data and then retrieve the spotify song_id if they match (we don't need to worry about duplicate songs e.g. songs released by an artist first as a single and then in an album since the songs should have the same features/genre etc).\n",
    "\n",
    "Additionally, we can extract the album id while we extract song id. This can potentially be useful for getting genre information. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Song_artist Object\n",
    "#### Creating object which stores song and artist data for later extraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from objects import song_artist\n",
    "\n",
    "# testing song_artist object\n",
    "sa = song_artist('move','brb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "move\n",
      "brb\n"
     ]
    }
   ],
   "source": [
    "print(sa.song)\n",
    "print(sa.artist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search-match function\n",
    "#### Creating a function which returns track_id\n",
    "This function will take in a `song_artist` object as a parameter and perform a search using the song and artist names. It then iterates through the returned tracks and matches our name-artist pair with one of the search outputs and returns the spotify `track_id` for that track. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_getid(worker, song_artist):\n",
    "    pair = song_artist.song + ' ' + song_artist.artist\n",
    "    temp = worker.search(pair)\n",
    "    end = len(temp['tracks']['items'])\n",
    "    for x in range(0,end):\n",
    "        #print(x)\n",
    "        #print(len(temp['tracks']['items']))\n",
    "        #print(temp['tracks']['items'])\n",
    "        out_track = temp['tracks']['items'][x]['name']\n",
    "        out_artist = temp['tracks']['items'][x]['artists'][0]['name']\n",
    "        track_id = temp['tracks']['items'][x]['id']\n",
    "        if ((song_artist.song == out_track) and (song_artist.artist == out_artist)):\n",
    "            return(track_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0G7xOaJtStqoAEyLKNuRA3\n",
      "My program took 0.31278347969055176 to run\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "temp = song_artist('The Weekend (with 347aidan) - Remix','88rising')\n",
    "\n",
    "print(search_getid(sp,temp)) #check passed \n",
    "\n",
    "print(\"My program took\", time.time() - start_time, \"to run\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding Track IDs to Streaming Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My initial attempt to complete this task used .apply to apply the function to the entire dataframe. However, this resulted in time out error where the cell would be stuck running but the api was not responsive. As a result, I believe it is not possible to apply the function to the entire dataframe. My next attempt is to split the dataframe up and apply the function to each part, changing the client_id and client_secret as needed. Finally, I decided to parallelize the operation while also simultaneously extracting audio_features and genre information. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Attempt 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import time\n",
    "#start_time = time.time()\n",
    "\n",
    "#df_ids = strm_base\n",
    "#df_ids['trackIDs'] = df_ids.apply(lambda x: search_getid(x['trackName'], x['artistName']), axis=1)\n",
    "\n",
    "#print(\"My program took\", time.time() - start_time, \"to run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_ids.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Attempt 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start_time = time.time()\n",
    "\n",
    "#df_1 = strm_base.iloc[0:5000,:]\n",
    "#df_1['trackIDs'] = df_1.apply(lambda x: search_getid(x['trackName'], x['artistName']), axis=1)\n",
    "\n",
    "#print(\"My program took\", time.time() - start_time, \"to run\") # My program took 661.2164733409882 to run\n",
    "# approx 11 min runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_1.to_csv(path_or_buf='data/ids_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1657764701.4609902\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nfor alt in range(0,5):\\n    cid, secret = alt_creds(alt)\\n    client_credentials_manager = SpotifyClientCredentials(client_id=cid,client_secret=secret)\\n    sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)\\n    \\n    if (alt == 0):\\n        start = (alt) * (strm_base.shape[0]/5)\\n    else:\\n        start = (alt) * (strm_base.shape[0]/5) + 1\\n    if (alt ==4):\\n        end = strm_base.shape[0]\\n    else:\\n        end = math.floor((alt+1) * (strm_base.shape[0]/5))\\n    \\n    df=strm_base.iloc[int(start):int(end),:]\\n    df[\\'trackIDs\\'] = df.apply(lambda x: search_getid(x[\\'trackName\\'], x[\\'artistName\\']), axis=1)\\n    \\n    path = \\'data/ids_\\' + str(alt) + \\'.csv\\'\\n    df.to_csv(path_or_buf=path)\\n\\nprint(\"My program took\", time.time() - start_time, \"to run\")'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dev_creds import alt_creds\n",
    "import math\n",
    "\n",
    "start_time = time.time()\n",
    "print(start_time)\n",
    "'''\n",
    "for alt in range(0,5):\n",
    "    cid, secret = alt_creds(alt)\n",
    "    client_credentials_manager = SpotifyClientCredentials(client_id=cid,client_secret=secret)\n",
    "    sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)\n",
    "    \n",
    "    if (alt == 0):\n",
    "        start = (alt) * (strm_base.shape[0]/5)\n",
    "    else:\n",
    "        start = (alt) * (strm_base.shape[0]/5) + 1\n",
    "    if (alt ==4):\n",
    "        end = strm_base.shape[0]\n",
    "    else:\n",
    "        end = math.floor((alt+1) * (strm_base.shape[0]/5))\n",
    "    \n",
    "    df=strm_base.iloc[int(start):int(end),:]\n",
    "    df['trackIDs'] = df.apply(lambda x: search_getid(x['trackName'], x['artistName']), axis=1)\n",
    "    \n",
    "    path = 'data/ids_' + str(alt) + '.csv'\n",
    "    df.to_csv(path_or_buf=path)\n",
    "\n",
    "print(\"My program took\", time.time() - start_time, \"to run\")''' # full loop takes around an hour to run, each iteration takes around 9-11 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_ids = pd.DataFrame()\n",
    "for file in os.listdir(\"./data\"):\n",
    "    if file.startswith(\"ids_\"):\n",
    "        file_path = \"./data/\" + file\n",
    "        temp = pd.read_csv(file_path)\n",
    "        full_ids = pd.concat([full_ids,temp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 20582 entries, 0 to 4116\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Unnamed: 0  20582 non-null  int64 \n",
      " 1   endTime     20582 non-null  object\n",
      " 2   artistName  20582 non-null  object\n",
      " 3   trackName   20582 non-null  object\n",
      " 4   msPlayed    20582 non-null  int64 \n",
      " 5   trackIDs    20360 non-null  object\n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "full_ids.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>endTime</th>\n",
       "      <th>artistName</th>\n",
       "      <th>trackName</th>\n",
       "      <th>msPlayed</th>\n",
       "      <th>trackIDs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>67</td>\n",
       "      <td>2021-11-08 00:28:00</td>\n",
       "      <td>Life Kit</td>\n",
       "      <td>How To Wake Up Early, Even If You're Not A Mor...</td>\n",
       "      <td>1291310</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>126</td>\n",
       "      <td>2021-11-09 01:38:00</td>\n",
       "      <td>Alonestar</td>\n",
       "      <td>Raise Em Up (House Remix) (feat. Ed Sheeran)</td>\n",
       "      <td>1990</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>310</td>\n",
       "      <td>2021-11-17 03:25:00</td>\n",
       "      <td>Macro Musings with David Beckworth</td>\n",
       "      <td>03 - John Cochrane on Finance, the Fiscal Theo...</td>\n",
       "      <td>1287330</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>411</td>\n",
       "      <td>2021-11-22 22:12:00</td>\n",
       "      <td>Ben Rosett</td>\n",
       "      <td>Shadow Galaxy</td>\n",
       "      <td>157959</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>441</td>\n",
       "      <td>2021-11-23 08:04:00</td>\n",
       "      <td>Third Party</td>\n",
       "      <td>We Found Love</td>\n",
       "      <td>205714</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3434</th>\n",
       "      <td>19903</td>\n",
       "      <td>2021-11-02 03:23:00</td>\n",
       "      <td>Alonestar</td>\n",
       "      <td>Raise Em Up (House Remix) (feat. Ed Sheeran)</td>\n",
       "      <td>45518</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3535</th>\n",
       "      <td>20004</td>\n",
       "      <td>2022-04-29 21:38:00</td>\n",
       "      <td>nzev</td>\n",
       "      <td>Lay It Down</td>\n",
       "      <td>640</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3565</th>\n",
       "      <td>20034</td>\n",
       "      <td>2022-04-29 23:16:00</td>\n",
       "      <td>DAWNBRINGERS</td>\n",
       "      <td>wishing</td>\n",
       "      <td>1400</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3566</th>\n",
       "      <td>20035</td>\n",
       "      <td>2022-04-29 23:16:00</td>\n",
       "      <td>DAWNBRINGERS</td>\n",
       "      <td>wishing</td>\n",
       "      <td>26180</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3930</th>\n",
       "      <td>20399</td>\n",
       "      <td>2022-05-08 04:51:00</td>\n",
       "      <td>nzev</td>\n",
       "      <td>Lay It Down</td>\n",
       "      <td>41088</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>222 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0              endTime                          artistName  \\\n",
       "67            67  2021-11-08 00:28:00                            Life Kit   \n",
       "126          126  2021-11-09 01:38:00                           Alonestar   \n",
       "310          310  2021-11-17 03:25:00  Macro Musings with David Beckworth   \n",
       "411          411  2021-11-22 22:12:00                          Ben Rosett   \n",
       "441          441  2021-11-23 08:04:00                         Third Party   \n",
       "...          ...                  ...                                 ...   \n",
       "3434       19903  2021-11-02 03:23:00                           Alonestar   \n",
       "3535       20004  2022-04-29 21:38:00                                nzev   \n",
       "3565       20034  2022-04-29 23:16:00                        DAWNBRINGERS   \n",
       "3566       20035  2022-04-29 23:16:00                        DAWNBRINGERS   \n",
       "3930       20399  2022-05-08 04:51:00                                nzev   \n",
       "\n",
       "                                              trackName  msPlayed trackIDs  \n",
       "67    How To Wake Up Early, Even If You're Not A Mor...   1291310      NaN  \n",
       "126        Raise Em Up (House Remix) (feat. Ed Sheeran)      1990      NaN  \n",
       "310   03 - John Cochrane on Finance, the Fiscal Theo...   1287330      NaN  \n",
       "411                                       Shadow Galaxy    157959      NaN  \n",
       "441                                       We Found Love    205714      NaN  \n",
       "...                                                 ...       ...      ...  \n",
       "3434       Raise Em Up (House Remix) (feat. Ed Sheeran)     45518      NaN  \n",
       "3535                                        Lay It Down       640      NaN  \n",
       "3565                                            wishing      1400      NaN  \n",
       "3566                                            wishing     26180      NaN  \n",
       "3930                                        Lay It Down     41088      NaN  \n",
       "\n",
       "[222 rows x 6 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_ids[pd.isnull(full_ids['trackIDs'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start_time = time.time()\n",
    "\n",
    "#df_2 = strm_base.iloc[5001:10000,:]\n",
    "#df_2['trackIDs'] = df_2.apply(lambda x: search_getid(x['trackName'], x['artistName']), axis=1)\n",
    "\n",
    "#print(\"My program took\", time.time() - start_time, \"to run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start_time = time.time()\n",
    "\n",
    "#df_3 = strm_base.iloc[10001:15000,:]\n",
    "#df_3['trackIDs'] = df_3.apply(lambda x: search_getid(x['trackName'], x['artistName']), axis=1)\n",
    "\n",
    "#print(\"My program took\", time.time() - start_time, \"to run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start_time = time.time()\n",
    "\n",
    "#df_4 = strm_base.iloc[15000:strm_base.shape[0],:]\n",
    "#df_4['trackIDs'] = df_4.apply(lambda x: search_getid(x['trackName'], x['artistName']), axis=1)\n",
    "\n",
    "#print(\"My program took\", time.time() - start_time, \"to run\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallelization of Operations\n",
    "\n",
    "Here, we adapt the methods used in parallelization of selenium webdriver scraping operations to matching track ids and adding features to each song. We first explore how features are added to determine how to best add it to the dataframe and then add this to the parallel operation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploring Adding Features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa = song_artist('free love','HONNE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0GPJSHYaXh8rZSSJoUMgyl\n"
     ]
    }
   ],
   "source": [
    "from methods import search_getid\n",
    "\n",
    "song_id = search_getid(sp,sa)\n",
    "print(song_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = sp.audio_features(song_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'danceability': 0.708, 'energy': 0.68, 'key': 9, 'loudness': -8.203, 'mode': 1, 'speechiness': 0.0519, 'acousticness': 0.0625, 'instrumentalness': 0, 'liveness': 0.152, 'valence': 0.7, 'tempo': 133.947, 'type': 'audio_features', 'id': '0GPJSHYaXh8rZSSJoUMgyl', 'uri': 'spotify:track:0GPJSHYaXh8rZSSJoUMgyl', 'track_href': 'https://api.spotify.com/v1/tracks/0GPJSHYaXh8rZSSJoUMgyl', 'analysis_url': 'https://api.spotify.com/v1/audio-analysis/0GPJSHYaXh8rZSSJoUMgyl', 'duration_ms': 209280, 'time_signature': 4}]\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "print(feat)\n",
    "print(len(feat[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.708,\n",
       " 0.68,\n",
       " 9,\n",
       " -8.203,\n",
       " 1,\n",
       " 0.0519,\n",
       " 0.0625,\n",
       " 0,\n",
       " 0.152,\n",
       " 0.7,\n",
       " 133.947,\n",
       " 'audio_features',\n",
       " '0GPJSHYaXh8rZSSJoUMgyl',\n",
       " 'spotify:track:0GPJSHYaXh8rZSSJoUMgyl',\n",
       " 'https://api.spotify.com/v1/tracks/0GPJSHYaXh8rZSSJoUMgyl',\n",
       " 'https://api.spotify.com/v1/audio-analysis/0GPJSHYaXh8rZSSJoUMgyl',\n",
       " 209280,\n",
       " 4]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(feat[0].values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['danceability',\n",
       " 'energy',\n",
       " 'key',\n",
       " 'loudness',\n",
       " 'mode',\n",
       " 'speechiness',\n",
       " 'acousticness',\n",
       " 'instrumentalness',\n",
       " 'liveness',\n",
       " 'valence',\n",
       " 'tempo',\n",
       " 'type',\n",
       " 'id',\n",
       " 'uri',\n",
       " 'track_href',\n",
       " 'analysis_url',\n",
       " 'duration_ms',\n",
       " 'time_signature']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(feat[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'duration_ms', 'time_signature']\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "temp = list(feat[0].keys())\n",
    "del temp[-7:-2]\n",
    "print(temp)\n",
    "print(len(temp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Findings**:\n",
    "\n",
    "It appears that `audio_features` returns a list of length one containing a dictionary of the features of the track given a track id. We can extract and get the relevant features by converting the dictionary values into a list for writing into a csv. The column names of the csv can also be created by the same method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploring Getting Genre Info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*via album*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1ATL5GLyefJaxhQzSPVrLX'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = sp.search('gods plan drake')\n",
    "s['tracks']['items'][0]['album']['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "alb = s['tracks']['items'][0]['album']['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "alb_feat = sp.album(alb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['album_type', 'artists', 'available_markets', 'copyrights', 'external_ids', 'external_urls', 'genres', 'href', 'id', 'images', 'label', 'name', 'popularity', 'release_date', 'release_date_precision', 'total_tracks', 'tracks', 'type', 'uri'])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alb_feat.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alb_feat['genres']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*via artist*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'external_urls': {'spotify': 'https://open.spotify.com/artist/3TVXtAsR1Inumwj472S9r4'},\n",
       "  'href': 'https://api.spotify.com/v1/artists/3TVXtAsR1Inumwj472S9r4',\n",
       "  'id': '3TVXtAsR1Inumwj472S9r4',\n",
       "  'name': 'Drake',\n",
       "  'type': 'artist',\n",
       "  'uri': 'spotify:artist:3TVXtAsR1Inumwj472S9r4'}]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s['tracks']['items'][0]['artists']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_id = s['tracks']['items'][0]['artists'][0]['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "art_info = sp.artist(artist_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['external_urls', 'followers', 'genres', 'href', 'id', 'images', 'name', 'popularity', 'type', 'uri'])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "art_info.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['canadian hip hop', 'canadian pop', 'hip hop', 'rap', 'toronto rap']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "art_info['genres']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sp.recommendation_genre_seeds()['genres'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Findings**:\n",
    "\n",
    "Strangely, it appears that using albums returns no genre for a number of songs. As a result, this method of obtaining genre information may be unreliable. We will test this further on the rest of the dataset. Additionally, using artist to get genre information appears to be too broad of a measure, with a number of genres listed that may not be indicative of the genre of the given song. \n",
    "\n",
    "Depending on how further testing of the album method goes, one potential solution could be to supplement spotify data with genre information from another website(s). This would require implementing some kind of webscraping algorithm to iterate through the list of song+artist pairs and extract genre information. \n",
    "\n",
    "Upon further research [online](https://community.spotify.com/t5/Spotify-for-Developers/Getting-album-not-getting-genre/td-p/5093156), it appears that neither tracks nor albums have genre data population, and assigning aggregate artist genre tags to individual tracks would most likely result in inaccurate analyses. As a result, I plan on exploring workarounds so that I can add genre data to my dataset e.g. webscraping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parallelization \n",
    "\n",
    "**Creating Method for Audio Feature Extraction**\n",
    "\n",
    "This method takes in a spotipy worker/object and a track id and returns a list of the relevant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(worker, track_id):\n",
    "    ft = worker.audio_features(track_id)\n",
    "    feats = list(ft[0].values())\n",
    "    del feats[-7:-2]\n",
    "    \n",
    "    return(feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.708, 0.68, 9, -8.203, 1, 0.0519, 0.0625, 0, 0.152, 0.7, 133.947, 209280, 4]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_features(sp,song_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initalizing Table**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_og = ['song_artist','track_id']\n",
    "col_feat = list(feat[0].keys())\n",
    "del col_feat[-7:-2]\n",
    "col_names = col_og + col_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('./modified/id_feats.csv', 'w')\n",
    "writer = csv.writer(file)\n",
    "writer.writerow(col_names)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Performing Operation**\n",
    "\n",
    "The `parallel` function takes in a list of data, here song_artist objects, and a function name, here `id_feats`. It will iterate through the song_artist objects utilizing each spotipy worker and return a completed link table which uses song_artist objects as the key.\n",
    "\n",
    "First we must create the column of song_artist objects that will be the input for this operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from objects import song_artist\n",
    "\n",
    "strm_base['song_artist'] = strm_base.apply(lambda x: song_artist(x['trackName'], x['artistName']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = strm_base['song_artist'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom parallelization import parallel\\nfrom methods import id_feats\\nstart_time = time.time()\\n\\nparallel(data,id_feats)\\n\\nprint(\"Table creation took\", time.time()-start_time, \"to run\") # 1996.9691202640533 (33 min) for entire run\\n'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from parallelization import parallel\n",
    "from methods import id_feats\n",
    "start_time = time.time()\n",
    "\n",
    "parallel(data,id_feats)\n",
    "\n",
    "print(\"Table creation took\", time.time()-start_time, \"to run\") # 1996.9691202640533 (33 min) for entire run\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring Supplementary Genre Data\n",
    "\n",
    "#### Webscraping\n",
    "\n",
    "In this section, we explore using webscraping as a method to obtain track-level genre data.\n",
    "\n",
    "*Website 1: [last.fm](https://www.last.fm/)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial inspection of last.fm reveals fairly comprehensive genre data. However, you cannot directly scrape this from the search feature. You must navigate to the song page itself in order to get this information. As a result, there may be significant trial and error when attempting to create a standard query to get track info from lastfm.\n",
    "\n",
    "With a simple song e.g. free love by HONNE, the query is formatted like this: https://www.last.fm/music/HONNE/_/free+love\n",
    "\n",
    "For an artist with a two-word name e.g. Jet Fuel by Mac Miller: https://www.last.fm/music/Mac+Miller/_/Jet+Fuel\n",
    "\n",
    "Track with multiple artists e.g. Nerdy Love by pH-1 and Yerin Baek: https://www.last.fm/music/pH-1,+Yerin+Baek/_/Nerdy+Love (interestingly, this is not actually the first song that comes up when you search 'Nerdy Love pH-1 Yerin Baek', it is actually https://www.last.fm/music/pH-1/_/Nerdy+Love+(feat.+Yerin+Baek))\n",
    "\n",
    "For our dataset, we only get the first artist from Spotify when there is more than one artist on the song. With the last.fm format, it seems that they are created with https://www.last.fm/music/ + artist + /_ / + track, where the track name replaces spaces with + and maintains capitalization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *last.fm* Query and Extraction:\n",
    "\n",
    "We create a function which makes a formatted artist and song query to feed into last.fm and scrape the page to extract genre information. While last.fm provides a number of tags/genres, we will only select the first one since it appears sorted by relevance as opposed to alphabetical order. This function takes in a `song_artist` object and returns the genre of the track."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "song = sa.song\n",
    "artist = sa.artist\n",
    "    \n",
    "artist_query = \"+\".join(artist.split(\" \"))\n",
    "song_query = \"+\".join(song.split(\" \"))\n",
    "    \n",
    "query = 'https://www.last.fm/music/' + artist_query + '/_/' + song_query\n",
    "    \n",
    "req = requests.get(query)\n",
    "sample = BeautifulSoup(req.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'alternative rnb'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "section = sample.find(name='section', class_ = 'catalogue-tags')\n",
    "section.find(name='li').string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_genre(song_artist):\n",
    "    song = song_artist.song\n",
    "    artist = song_artist.artist\n",
    "    \n",
    "    artist_query = \"+\".join(artist.split(\" \"))\n",
    "    song_query = \"+\".join(song.split(\" \"))\n",
    "    \n",
    "    query = 'https://www.last.fm/music/' + artist_query + '/_/' + song_query\n",
    "    \n",
    "    req = requests.get(query)\n",
    "    sample = BeautifulSoup(req.content, 'html.parser')\n",
    "    \n",
    "    try:\n",
    "        section = sample.find(name='section', class_ = 'catalogue-tags')\n",
    "        genre = section.find(name='li').string\n",
    "    except:\n",
    "        genre = np.nan\n",
    "    \n",
    "    return genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'alternative rnb'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_genre(sa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *last.fm* genre extraction test\n",
    "\n",
    "Here we test our function on a subset of the data (100 entries)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nstart_time = time.time()\\n\\ngenre_test = strm_base.iloc[0:100,:].apply(lambda x: get_genre(x[\\'song_object\\']), axis=1)\\n\\nprint(\"My program took\", time.time() - start_time, \"to run\") # old code took 42s to scrape 100 genres\\n\\n'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "genre_test = strm_base.iloc[0:100,:].apply(lambda x: get_genre(x['song_object']), axis=1)\n",
    "\n",
    "print(\"My program took\", time.time() - start_time, \"to run\") # old code took 42s to scrape 100 genres\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(genre_test[pd.isnull(genre_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(genre_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#strings = [~isinstance(n, str) for n in genre_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for x in genre_test:\n",
    "#    print(type(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Genre Data to Dataset\n",
    "\n",
    "#### *last.fm* Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom methods import get_genre\\nimport threading\\n\\nfile = open(\\'./modified/genres.csv\\', \\'w\\')\\nwriter = csv.writer(file)\\nwriter.writerow([\\'song_artist\\',\\'genre\\'])\\nfile.close()\\n\\nstart_time = time.time()\\n\\nstrm_base.apply(lambda x: get_genre(x[\\'song_artist\\']), axis=1)\\n\\nprint(\"My program took\", time.time() - start_time, \"to run\") # 51.85 for 100 genres writing to csv\\n# 6545.196605205536 (1hr 49min) for full 20586 to csv\\n'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from methods import get_genre\n",
    "import threading\n",
    "\n",
    "file = open('./modified/genres.csv', 'w')\n",
    "writer = csv.writer(file)\n",
    "writer.writerow(['song_artist','genre'])\n",
    "file.close()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "strm_base.apply(lambda x: get_genre(x['song_artist']), axis=1)\n",
    "\n",
    "print(\"My program took\", time.time() - start_time, \"to run\") # 51.85 for 100 genres writing to csv\n",
    "# 6545.196605205536 (1hr 49min) for full 20586 to csv\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining Methods\n",
    "\n",
    "#### Creating new table and merging with stream_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20586 entries, 0 to 20585\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype         \n",
      "---  ------       --------------  -----         \n",
      " 0   endTime      20586 non-null  datetime64[ns]\n",
      " 1   artistName   20586 non-null  string        \n",
      " 2   trackName    20586 non-null  string        \n",
      " 3   msPlayed     20586 non-null  int64         \n",
      " 4   song_artist  20586 non-null  object        \n",
      "dtypes: datetime64[ns](1), int64(1), object(1), string(2)\n",
      "memory usage: 804.3+ KB\n"
     ]
    }
   ],
   "source": [
    "strm_base.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20586"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(col_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['track_id'] + col_feat + ['genre']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('./modified/full_table.csv', 'w')\n",
    "writer = csv.writer(file)\n",
    "writer.writerow(columns)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Error for GET to https://api.spotify.com/v1/search with Params: {'q': 'The Restructuring of the LCS Players Association feat. Jacob Wolf FTW with Imad Khan: An Esports and Competitive Gaming Podcast', 'limit': 10, 'offset': 0, 'type': 'track', 'market': None} returned 404 due to Not found.\n",
      "HTTP Error for GET to https://api.spotify.com/v1/search with Params: {'q': 'The Significance of the Sinatraa Suspension feat. Hunter Cooke FTW with Imad Khan: An Esports and Competitive Gaming Podcast', 'limit': 10, 'offset': 0, 'type': 'track', 'market': None} returned 404 due to Not found.\n",
      "HTTP Error for GET to https://api.spotify.com/v1/search with Params: {'q': 'The Restructuring of the LCS Players Association feat. Jacob Wolf FTW with Imad Khan: An Esports and Competitive Gaming Podcast', 'limit': 10, 'offset': 0, 'type': 'track', 'market': None} returned 404 due to Not found.\n",
      "HTTP Error for GET to https://api.spotify.com/v1/search with Params: {'q': 'Crazy Noisy Bizarre Town (From \"Jojo\\'s Bizarre Adventure: Diamond Is Unbreakable\") [feat. Skully Tun] Chipmusic Heroes', 'limit': 10, 'offset': 0, 'type': 'track', 'market': None} returned 404 due to Not found.\n",
      "HTTP Error for GET to https://api.spotify.com/v1/search with Params: {'q': 'Steffen Murau on the Eurozone, International Monetary Architecture, and the Future of the Dollar Zone Macro Musings with David Beckworth', 'limit': 10, 'offset': 0, 'type': 'track', 'market': None} returned 404 due to Not found.\n",
      "HTTP Error for GET to https://api.spotify.com/v1/search with Params: {'q': 'Crazy Noisy Bizarre Town (From \"Jojo\\'s Bizarre Adventure: Diamond Is Unbreakable\") [feat. Skully Tun] Chipmusic Heroes', 'limit': 10, 'offset': 0, 'type': 'track', 'market': None} returned 404 due to Not found.\n",
      "HTTP Error for GET to https://api.spotify.com/v1/search with Params: {'q': 'Crazy Noisy Bizarre Town (From \"Jojo\\'s Bizarre Adventure: Diamond Is Unbreakable\") [feat. Skully Tun] Chipmusic Heroes', 'limit': 10, 'offset': 0, 'type': 'track', 'market': None} returned 404 due to Not found.\n",
      "HTTP Error for GET to https://api.spotify.com/v1/search with Params: {'q': 'Crazy Noisy Bizarre Town (From \"Jojo\\'s Bizarre Adventure: Diamond Is Unbreakable\") [feat. Skully Tun] Chipmusic Heroes', 'limit': 10, 'offset': 0, 'type': 'track', 'market': None} returned 404 due to Not found.\n",
      "HTTP Error for GET to https://api.spotify.com/v1/search with Params: {'q': 'Crazy Noisy Bizarre Town (From \"Jojo\\'s Bizarre Adventure: Diamond Is Unbreakable\") [feat. Skully Tun] Chipmusic Heroes', 'limit': 10, 'offset': 0, 'type': 'track', 'market': None} returned 404 due to Not found.\n",
      "HTTP Error for GET to https://api.spotify.com/v1/search with Params: {'q': 'Jason Furman on Overheating, Inflation, and Fiscal Policy in an Era of Low Interest Rates Macro Musings with David Beckworth', 'limit': 10, 'offset': 0, 'type': 'track', 'market': None} returned 404 due to Not found.\n",
      "HTTP Error for GET to https://api.spotify.com/v1/search with Params: {'q': 'Jerusalem Demsas on Problems in the US Housing Market and How to Fix Them Macro Musings with David Beckworth', 'limit': 10, 'offset': 0, 'type': 'track', 'market': None} returned 404 due to Not found.\n",
      "HTTP Error for GET to https://api.spotify.com/v1/search with Params: {'q': 'Agustin Carstens on Central Banking in Emerging Markets, the Distributional Footprint of Monetary Policy, and Central Bank Digital Currency Macro Musings with David Beckworth', 'limit': 10, 'offset': 0, 'type': 'track', 'market': None} returned 404 due to Not found.\n",
      "HTTP Error for GET to https://api.spotify.com/v1/search with Params: {'q': 'Jerusalem Demsas on Problems in the US Housing Market and How to Fix Them Macro Musings with David Beckworth', 'limit': 10, 'offset': 0, 'type': 'track', 'market': None} returned 404 due to Not found.\n",
      "HTTP Error for GET to https://api.spotify.com/v1/search with Params: {'q': 'Skanda Amarnath on Maximum Employment, Inflation, and the Fed’s New Framework Macro Musings with David Beckworth', 'limit': 10, 'offset': 0, 'type': 'track', 'market': None} returned 404 due to Not found.\n",
      "HTTP Error for GET to https://api.spotify.com/v1/search with Params: {'q': 'The Financially Fragile Future of the Overwatch (2) League feat. Jacob Wolf FTW with Imad Khan: An Esports and Competitive Gaming Podcast', 'limit': 10, 'offset': 0, 'type': 'track', 'market': None} returned 404 due to Not found.\n",
      "HTTP Error for GET to https://api.spotify.com/v1/search with Params: {'q': 'Skanda Amarnath on Maximum Employment, Inflation, and the Fed’s New Framework Macro Musings with David Beckworth', 'limit': 10, 'offset': 0, 'type': 'track', 'market': None} returned 404 due to Not found.\n",
      "HTTP Error for GET to https://api.spotify.com/v1/search with Params: {'q': 'Jerusalem Demsas on Problems in the US Housing Market and How to Fix Them Macro Musings with David Beckworth', 'limit': 10, 'offset': 0, 'type': 'track', 'market': None} returned 404 due to Not found.\n",
      "HTTP Error for GET to https://api.spotify.com/v1/search with Params: {'q': 'Scott Sumner on What Milton Friedman Would Think of Monetary Policy Today Macro Musings with David Beckworth', 'limit': 10, 'offset': 0, 'type': 'track', 'market': None} returned 404 due to Not found.\n",
      "HTTP Error for GET to https://api.spotify.com/v1/search with Params: {'q': 'Scott Sumner on What Milton Friedman Would Think of Monetary Policy Today Macro Musings with David Beckworth', 'limit': 10, 'offset': 0, 'type': 'track', 'market': None} returned 404 due to Not found.\n",
      "HTTP Error for GET to https://api.spotify.com/v1/search with Params: {'q': 'Kate Judge and Anil Kashyap on How to Improve US Financial Stability Macro Musings with David Beckworth', 'limit': 10, 'offset': 0, 'type': 'track', 'market': None} returned 404 due to Not found.\n",
      "HTTP Error for GET to https://api.spotify.com/v1/search with Params: {'q': 'Kate Judge and Anil Kashyap on How to Improve US Financial Stability Macro Musings with David Beckworth', 'limit': 10, 'offset': 0, 'type': 'track', 'market': None} returned 404 due to Not found.\n",
      "HTTP Error for GET to https://api.spotify.com/v1/search with Params: {'q': 'Kate Judge and Anil Kashyap on How to Improve US Financial Stability Macro Musings with David Beckworth', 'limit': 10, 'offset': 0, 'type': 'track', 'market': None} returned 404 due to Not found.\n",
      "HTTP Error for GET to https://api.spotify.com/v1/search with Params: {'q': 'Hanno Lustig on Dollar Dominance, Dollar Safety, and the Global Financial Cycle Macro Musings with David Beckworth', 'limit': 10, 'offset': 0, 'type': 'track', 'market': None} returned 404 due to Not found.\n",
      "HTTP Error for GET to https://api.spotify.com/v1/search with Params: {'q': 'Hanno Lustig on Dollar Dominance, Dollar Safety, and the Global Financial Cycle Macro Musings with David Beckworth', 'limit': 10, 'offset': 0, 'type': 'track', 'market': None} returned 404 due to Not found.\n",
      "HTTP Error for GET to https://api.spotify.com/v1/search with Params: {'q': 'Hanno Lustig on Dollar Dominance, Dollar Safety, and the Global Financial Cycle Macro Musings with David Beckworth', 'limit': 10, 'offset': 0, 'type': 'track', 'market': None} returned 404 due to Not found.\n",
      "HTTP Error for GET to https://api.spotify.com/v1/search with Params: {'q': 'Chris Russo on the 2021 Debt Limit Fight, Its Potential Impacts, and Solutions for Reform Macro Musings with David Beckworth', 'limit': 10, 'offset': 0, 'type': 'track', 'market': None} returned 404 due to Not found.\n",
      "HTTP Error for GET to https://api.spotify.com/v1/search with Params: {'q': 'Crazy Noisy Bizarre Town (From \"Jojo\\'s Bizarre Adventure: Diamond Is Unbreakable\") [feat. Skully Tun] Chipmusic Heroes', 'limit': 10, 'offset': 0, 'type': 'track', 'market': None} returned 404 due to Not found.\n",
      "HTTP Error for GET to https://api.spotify.com/v1/search with Params: {'q': '03 - John Cochrane on Finance, the Fiscal Theory of the Price Level, and Blogging Macro Musings with David Beckworth', 'limit': 10, 'offset': 0, 'type': 'track', 'market': None} returned 404 due to Not found.\n",
      "HTTP Error for GET to https://api.spotify.com/v1/search with Params: {'q': 'Crazy Noisy Bizarre Town (From \"Jojo\\'s Bizarre Adventure: Diamond Is Unbreakable\") [feat. Skully Tun] Chipmusic Heroes', 'limit': 10, 'offset': 0, 'type': 'track', 'market': None} returned 404 due to Not found.\n",
      "HTTP Error for GET to https://api.spotify.com/v1/search with Params: {'q': 'Crazy Noisy Bizarre Town (From \"Jojo\\'s Bizarre Adventure: Diamond Is Unbreakable\") [feat. Skully Tun] Chipmusic Heroes', 'limit': 10, 'offset': 0, 'type': 'track', 'market': None} returned 404 due to Not found.\n",
      "HTTP Error for GET to https://api.spotify.com/v1/search with Params: {'q': 'Yesha Yadav on the Fragilities in the Treasury Market and Solutions for Reform Macro Musings with David Beckworth', 'limit': 10, 'offset': 0, 'type': 'track', 'market': None} returned 404 due to Not found.\n",
      "HTTP Error for GET to https://api.spotify.com/v1/search with Params: {'q': 'Lorie Logan on Monetary Policy Operations, the Fed’s New Standing Repo Facility, and the Future of the Fed’s Balance Sheet Macro Musings with David Beckworth', 'limit': 10, 'offset': 0, 'type': 'track', 'market': None} returned 404 due to Not found.\n",
      "HTTP Error for GET to https://api.spotify.com/v1/search with Params: {'q': 'David Beckworth on the Safe Asset Theory of Inflation, Comparing Central Bank Frameworks, and a Year of Macro Musings in Review Macro Musings with David Beckworth', 'limit': 10, 'offset': 0, 'type': 'track', 'market': None} returned 404 due to Not found.\n",
      "HTTP Error for GET to https://api.spotify.com/v1/search with Params: {'q': 'David Beckworth on the Safe Asset Theory of Inflation, Comparing Central Bank Frameworks, and a Year of Macro Musings in Review Macro Musings with David Beckworth', 'limit': 10, 'offset': 0, 'type': 'track', 'market': None} returned 404 due to Not found.\n",
      "HTTP Error for GET to https://api.spotify.com/v1/search with Params: {'q': 'Lorie Logan on Monetary Policy Operations, the Fed’s New Standing Repo Facility, and the Future of the Fed’s Balance Sheet Macro Musings with David Beckworth', 'limit': 10, 'offset': 0, 'type': 'track', 'market': None} returned 404 due to Not found.\n",
      "HTTP Error for GET to https://api.spotify.com/v1/search with Params: {'q': 'George Selgin on the Future of CBDC, Fed Accounts, and Stablecoins Macro Musings with David Beckworth', 'limit': 10, 'offset': 0, 'type': 'track', 'market': None} returned 404 due to Not found.\n",
      "HTTP Error for GET to https://api.spotify.com/v1/search with Params: {'q': 'Crazy Noisy Bizarre Town (From \"Jojo\\'s Bizarre Adventure: Diamond Is Unbreakable\") [feat. Skully Tun] Chipmusic Heroes', 'limit': 10, 'offset': 0, 'type': 'track', 'market': None} returned 404 due to Not found.\n",
      "HTTP Error for GET to https://api.spotify.com/v1/search with Params: {'q': 'Lubos Pastor and Elisabeth Kempf on *Fifty Shades of QE* and the Implications of QE Research Macro Musings with David Beckworth', 'limit': 10, 'offset': 0, 'type': 'track', 'market': None} returned 404 due to Not found.\n",
      "HTTP Error for GET to https://api.spotify.com/v1/search with Params: {'q': 'Lubos Pastor and Elisabeth Kempf on *Fifty Shades of QE* and the Implications of QE Research Macro Musings with David Beckworth', 'limit': 10, 'offset': 0, 'type': 'track', 'market': None} returned 404 due to Not found.\n",
      "HTTP Error for GET to https://api.spotify.com/v1/search with Params: {'q': 'Tear Up This Town - Orchestral Version / From \"A Monster Calls\" Original Motion Picture Soundtrack Keane', 'limit': 10, 'offset': 0, 'type': 'track', 'market': None} returned 404 due to Not found.\n",
      "HTTP Error for GET to https://api.spotify.com/v1/search with Params: {'q': 'Will Diamond on Safe Assets, Risk-Free Rates, and Convenience Yields and their Implications for Policy Macro Musings with David Beckworth', 'limit': 10, 'offset': 0, 'type': 'track', 'market': None} returned 404 due to Not found.\n",
      "HTTP Error for GET to https://api.spotify.com/v1/search with Params: {'q': 'Joey Politano on Recent Inflationary Trends and the Future Outlook for Monetary Policy Macro Musings with David Beckworth', 'limit': 10, 'offset': 0, 'type': 'track', 'market': None} returned 404 due to Not found.\n",
      "HTTP Error for GET to https://api.spotify.com/v1/search with Params: {'q': 'Joey Politano on Recent Inflationary Trends and the Future Outlook for Monetary Policy Macro Musings with David Beckworth', 'limit': 10, 'offset': 0, 'type': 'track', 'market': None} returned 404 due to Not found.\n",
      "HTTP Error for GET to https://api.spotify.com/v1/search with Params: {'q': 'Joey Politano on Recent Inflationary Trends and the Future Outlook for Monetary Policy Macro Musings with David Beckworth', 'limit': 10, 'offset': 0, 'type': 'track', 'market': None} returned 404 due to Not found.\n",
      "HTTP Error for GET to https://api.spotify.com/v1/search with Params: {'q': 'Colin Grabow on Current Trends in US Trade Policy and the Adverse Impact of the Jones Act Macro Musings with David Beckworth', 'limit': 10, 'offset': 0, 'type': 'track', 'market': None} returned 404 due to Not found.\n",
      "STOP encountered, killing worker thread\n",
      "STOP encountered, killing worker thread\n",
      "STOP encountered, killing worker thread\n",
      "STOP encountered, killing worker thread\n",
      "STOP encountered, killing worker thread\n",
      "STOP encountered, killing worker thread\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table creation took 5117.0232944488525 to run\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\matth\\anaconda3\\lib\\multiprocessing\\queues.py\", line 238, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"C:\\Users\\matth\\anaconda3\\lib\\multiprocessing\\connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"C:\\Users\\matth\\anaconda3\\lib\\multiprocessing\\connection.py\", line 280, in _send_bytes\n",
      "    ov, err = _winapi.WriteFile(self._handle, buf, overlapped=True)\n",
      "BrokenPipeError: [WinError 232] The pipe is being closed\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from parallelization import parallel\n",
    "from methods import create_table\n",
    "start_time = time.time()\n",
    "\n",
    "parallel(data,create_table)\n",
    "\n",
    "print(\"Table creation took\", time.time()-start_time, \"to run\") # full 5117.0232944488525 (1hr 25m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_table = pd.read_csv('./modified/full_table.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 20576 entries, nan to 648sjoR2ga0PXixXttyqzJ\n",
      "Data columns (total 15 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   track_id          20300 non-null  float64\n",
      " 1   danceability      20300 non-null  object \n",
      " 2   energy            20299 non-null  float64\n",
      " 3   key               20299 non-null  float64\n",
      " 4   loudness          20299 non-null  float64\n",
      " 5   mode              20299 non-null  object \n",
      " 6   speechiness       20298 non-null  float64\n",
      " 7   acousticness      20298 non-null  float64\n",
      " 8   instrumentalness  20298 non-null  float64\n",
      " 9   liveness          20298 non-null  float64\n",
      " 10  valence           20298 non-null  float64\n",
      " 11  tempo             20298 non-null  float64\n",
      " 12  duration_ms       20298 non-null  float64\n",
      " 13  time_signature    14061 non-null  object \n",
      " 14  genre             98 non-null     object \n",
      "dtypes: float64(11), object(4)\n",
      "memory usage: 3.1+ MB\n"
     ]
    }
   ],
   "source": [
    "add_table.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (656686, 17), indices imply (41162, 17)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-82-5c500c91b5be>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcomb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstrm_base\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'endTime'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'msPlayed'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0madd_table\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    282\u001b[0m     )\n\u001b[0;32m    283\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 284\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    285\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    286\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36mget_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    496\u001b[0m             new_data = concatenate_block_managers(\n\u001b[1;32m--> 497\u001b[1;33m                 \u001b[0mmgrs_indexers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew_axes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconcat_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    498\u001b[0m             )\n\u001b[0;32m    499\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mconcatenate_block_managers\u001b[1;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[0;32m   2025\u001b[0m         \u001b[0mblocks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2026\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2027\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mBlockManager\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, blocks, axes, do_integrity_check)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdo_integrity_check\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_verify_integrity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_consolidate_check\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36m_verify_integrity\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    332\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mblock\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    333\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_verify_integrity\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mblock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mmgr_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 334\u001b[1;33m                 \u001b[0mconstruction_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtot_items\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    335\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mtot_items\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    336\u001b[0m             raise AssertionError(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mconstruction_error\u001b[1;34m(tot_items, block_shape, axes, e)\u001b[0m\n\u001b[0;32m   1692\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mblock_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1693\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Empty data passed with indices specified.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1694\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Shape of passed values is {passed}, indices imply {implied}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1695\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1696\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Shape of passed values is (656686, 17), indices imply (41162, 17)"
     ]
    }
   ],
   "source": [
    "comb = pd.concat([strm_base[['endTime','msPlayed']],add_table], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#comb.to_csv(path_or_buf = './modified/temp_post.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking songs that exist (have genre) but did not get a track id:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validating full table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = comb.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_ids = test[pd.isnull(test['track_id']) & ~pd.isnull(test['genre'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_ids['song_artist'] = no_ids.apply(lambda x: song_artist(x['trackName'], x['artistName']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rerun = no_ids['song_artist'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('./modified/rerun.csv', 'w')\n",
    "writer = csv.writer(file)\n",
    "writer.writerow(columns)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "parallel(rerun,create_table)\n",
    "\n",
    "print(\"Rerun took\", time.time()-start_time) # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rerun_res = pd.read_csv('./modified/rerun.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rerun_res.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking songs that did not receive a genre:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = comb.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_nas = test[pd.isnull(test['genre'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_nas[['artistName','trackName']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note*: There are a significant number of NAs after scraping genres. As a result, there is a need to either revise our method to get genre information or devise a method for imputation. \n",
    "\n",
    "**Possible Solution using Imputation**: Since it appears that there are artists who receive genre data for some songs and not others, one possible imputation method would be to create a dictionary where each artist corresponds to their top genre (can also scrape this from last.fm)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputing Genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from methods import table_artGen\n",
    "\n",
    "test_artists = add_table['artistName'][0:100].tolist()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "test_dict = {artist: table_artGen(artist) for artist in test_artists}\n",
    "\n",
    "print(\"My program took\", time.time() - start_time, \"to run\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_dict) == len(add_table.iloc[0:100,:]['artistName'].unique()) \n",
    "# using a dictionary means that duplicate artists are not created"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Potential Idea**: replace all nas in genre column with corresponding value in artist column and then replace the filled artist values with genres using the dictionary mentioned above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing replacing 'artist' values with genre**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = add_table.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.iloc[0:100,:]['artistName'].replace(test_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.iloc[0:100,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Making Artist:Genre Dictionary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "art_names = add_table['artistName'].unique().tolist()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "artGen_dict = {artist: table_artGen(artist) for artist in art_names}\n",
    "\n",
    "print(\"My program took\", time.time() - start_time, \"to run\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imputing Genres**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_table['genre'].fillna(add_table['artistName'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_table['genre'].replace(artGen_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing for Visualization and Analysis\n",
    "\n",
    "#### Data Cleaning + Tidying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
